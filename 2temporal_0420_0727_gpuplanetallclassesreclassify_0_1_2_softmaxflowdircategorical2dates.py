# -*- coding: utf-8 -*-
"""Temporal_0420_0727_GPUPlanetAllClassesReclassify_0_1_2_SoftmaxFlowDirCategorical2Dates.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lVxK_FaRqFzLX1Dfq8zmer0MHXduQ4eO

# Install Libraries on Google Colab, may need to restart runtime.
"""

!pip3 install --upgrade pip --user
!pip3 install keras --user
!pip3 install tensorflow --user
!pip3 install pydot --user
!pip3 install matplotlib --user
!pip3 install pillow --user
!pip3 install sklearn --user
!pip3 install segmentation-models --user
!pip3 install --upgrade wandb --user
!pip install gputil
!pip install psutil
!pip install humanize

"""# Mount Google Drive"""

# Mounting the Google Drive for data load
from google.colab import drive
drive.mount('/content/drive')

"""# Extract the zip files in the folder"""

# Extracting the zip files of train, test and validtion images into Colab drive

!jar xf '/content/drive/My Drive/home/uceshaf/FinalProject/datasets/PlanetTemporal/PlanetStack_0420_0727.zip'

"""# Import all libraies that are required or have been used"""

# compare f-beta score between sklearn and keras
print('Starting import of libraries')
import glob
import os
import numpy as np
from numpy import load, array_equal, array,expand_dims
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils.multiclass import unique_labels
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support

from skimage import io

from keras import backend
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D,Input
from keras.optimizers import SGD, Adam
from keras.models import Model
from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau
from keras.backend import set_session
  
from keras import backend as K

from keras.utils import multi_gpu_model, plot_model, to_categorical
print('keras loaded')
from segmentation_models import Unet,FPN, Linknet, PSPNet
from segmentation_models.backbones import get_preprocessing
from segmentation_models.losses import bce_jaccard_loss,jaccard_loss 
from segmentation_models.metrics import iou_score, f_score
print('segmentation models loaded')
import wandb
from wandb.keras import WandbCallback
print('weights and biases loaded')
import tensorflow as tf
import gc

import time
from datetime import datetime



"""# Login to the weights and Biases for Callbacks"""

projectname = '2_PlanetStack_0420_0727_Unet_AllClassesReclassify_buffered_0_1_2_CategoricalSoftmaxJaccard'
try:
    wandb.init(name=projectname,project='finalproject')
except:
    print('Could not initialize wandb')

"""# Check GPU memory and state"""

# memory footprint support libraries/code
!ln -sf 11opt/bin/nvidia-smi /usr/bin/nvidia-smi
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnâ€™t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )
sess = tf.Session(config=config) 
set_session(sess)
tf.test.gpu_device_name()

"""# Architectures and Backbones"""

# ##----##-----##-----##-----##----##
   #---##
Satellite = 'Planet'    #---##
Exp = 'Exp12'            #---##
# ##----##-----##-----##-----##----##

epochs = 15    ########
batch_size = 5   ######
rescale_bit = 65535.0   ###########
architectures = ['Unet', 'FPN', 'Linknet', 'PSPNet']

########### Weights of Imagenet #############
#weightusage = 'WgtNone'
weightusage = 'imagenet'

# ##----##-----##-----##-----##----##


backbones = [
#'vgg19',

#'seresnet152',
#'efficientnetb7',
'senet154',
#'resnet152',
#'resnet34',
#'resnext101'
#'seresnext101',
#'densenet201',
#'inceptionv3', 
#'mobilenetv2',
#'efficientnetb3',
#'inceptionresnetv2'
#'vgg16',
#'resnet18','resnet34',
#'resnet50', 'resnet101',
#'seresnet18', 'seresnet34', 'seresnet50', 'seresnet101',
#'resnext50',
#'seresnext50', 
#'densenet121', 'densenet169',
#'mobilenet',
#'efficientnetb0', 'efficientnetb1', 'efficientnetb2'
]
print('\n\n',backbones, '\n\n')

# -------------- ARCHITECTURES---------
architectures = [
'Unet',
#'FPN'
#'Linknet',
#'PSPNet'
]

print(architectures)

"""# Functions Defined Below"""

print(os.getcwd())
ids_train_split = os.listdir('train/tifs/images/')
print('Length of train ids ', len(ids_train_split))


ids_test_split = os.listdir('test/tifs/images/')
print('Length of test ids ', len(ids_test_split))


ids_val_split = os.listdir('val/tifs/images/')
print('Length of val ids ', len(ids_val_split))



def train_generator(ids_train_split, batch_size):
    while True:
        for start in range(0, len(ids_train_split), batch_size):
            x_batch = []
            y_batch = []
            end = min(start + batch_size, len(ids_train_split))
            ids_train_batch = ids_train_split[start:end]
            for id in ids_train_batch:
                #print('content/train/tifs/images/'+str(id))
                img = io.imread('train/tifs/images/'+str(id))
                mask = io.imread('train/labels/masks/'+str(id))
                mask = np.expand_dims(mask, axis=2)
                
                x_batch.append(img)
                y_batch.append(mask)
            x_batch = np.array(x_batch, np.float32) / 65535
            y_batch = to_categorical(y_batch)
            #print('Returning from batch')
            yield x_batch, y_batch
            
            
def test_generator(ids_test_split, batch_size):
    while True:
        for start in range(0, len(ids_test_split), batch_size):
            x_batch = []
            y_batch = []
            end = min(start + batch_size, len(ids_test_split))
            ids_test_batch = ids_test_split[start:end]
            for id in ids_test_batch:
                img = io.imread('test/tifs/images/'+str(id))
                mask = io.imread('test/labels/masks/'+str(id))
                mask = np.expand_dims(mask, axis=2)
                
                x_batch.append(img)
                y_batch.append(mask)
            x_batch = np.array(x_batch, np.float32) / 65535
            y_batch = to_categorical(y_batch)
            yield x_batch, y_batch
            
def val_generator(ids_val_split, batch_size):
    while True:
        for start in range(0, len(ids_val_split), batch_size):
            x_batch = []
            y_batch = []
            end = min(start + batch_size, len(ids_val_split))
            ids_val_batch = ids_val_split[start:end]
            for id in ids_val_batch:
                img = io.imread('val/tifs/images/'+str(id))
                mask = io.imread('val/labels/masks/'+str(id))
                mask = np.expand_dims(mask, axis=2)
                x_batch.append(img)
                y_batch.append(mask)
            x_batch = np.array(x_batch, np.float32) / 65535
            y_batch = to_categorical(y_batch)
            yield x_batch, y_batch
            


def recall_m(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        return recall

def precision_m(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))  
 


### define cnn model
def define_model(architecture='Unet', BACKBONE='resnet34', input_shape=(None, None, 4),encoder_weights=None):
    print('In define_model function')
    if architecture == 'Unet':
        model = Unet(BACKBONE, classes=3, activation='softmax', encoder_weights=encoder_weights, input_shape=input_shape)
        print('Unet model defined')
    elif architecture == 'FPN':
        model = FPN(BACKBONE, classes=3, activation='softmax', encoder_weights=encoder_weights, input_shape=input_shape)
        print('FPN model defined')
    elif architecture == 'Linknet':
        model = Linknet(BACKBONE, classes=3, activation='softmax', encoder_weights=encoder_weights, input_shape=input_shape)
        print('Linknet model defined')
    elif architecture == 'PSPNet':
        model = PSPNet(BACKBONE, classes=3, activation='softmax', encoder_weights=encoder_weights, input_shape=input_shape)
        print('PSPNet model defined')
    return model

def multi_gpu_compile(model):
    try:
        model = multi_gpu_model(model, gpus=1)
        print("\nTraining using multiple GPUs..\n")
    except Exception as e:
        print(e)
        print("\nTraining using single GPU or CPU..\n")
    print('returning gpu_model')
    return model


def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    classes = classes[unique_labels(y_true, y_pred)]
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

# # entry point, run the test harness

os.listdir('train/tifs/images')[1:5]

# Commented out IPython magic to ensure Python compatibility.
training = 'Yes'
predictions = 'Yes'
accuracies = 'Yes'

clstype='2_PlanetStack_0420_0727_AllClassesReclassify_buffered_0_1_2'

path = '/content/drive/My Drive/home/uceshaf/FinalProject/datasets/'

date = '20180420_20180727'

batch_size = 8

N = 8  # The number of channels


learning_rate=0.001


train_folder, train_mask_folder = 'train/tifs/images/','train/labels/masks/'
test_folder, test_mask_folder = 'test/tifs/images/','test/labels/masks/'
val_folder, val_mask_folder = 'val/tifs/images/','val/labels/masks/'


# -------------------------------------------------------------------------------------------
# -------------------------------------Main Run------------------------------------------------------
# -------------------------------------------------------------------------------------------

#Loop over all histories and run the model and then check accuarices/predictions
histories = {}
for architecture in architectures:
    print(architecture)
    for backbone in backbones:
        #wandb.init(project="finalproject")
        print(backbone)
        
        

        print(os.getcwd())
        # Getting the list of images in train and test and initailizing the generator
        ids_train_split = os.listdir(train_folder)
        print('Length of train ids ', len(ids_train_split))
        
        train_gen = train_generator(ids_train_split, batch_size)
        #valid_generator = get_generator(train_folder, train_mask_folder, 
                                                       # valid_folder, valid_mask_folder)
          
        ids_test_split = os.listdir(test_folder)
        print('Length of test ids ', len(ids_test_split))
        
        test_gen = test_generator(ids_test_split, batch_size)
        print(type(test_gen))
        print(type(train_gen))
        





        
        if weightusage == 'imagenet':
            base_model = define_model(architecture=architecture, input_shape=(None, None, 3), BACKBONE=backbone, encoder_weights='imagenet')
            inp = Input(shape=(None, None, N))
            l1 = Conv2D(6, (1, 1), name='1st_Conv')(inp) # map N channels data to 6 channels
            l2 = Conv2D(4, (1, 1), name='2nd_Conv')(l1) # map N channels data to 4 channels
            l3 = Conv2D(3, (1, 1), name='3rd_Conv')(l2) # map N channels data to 3 channels
            
            out = base_model(l3)
            print('Adding Conv Layer')
            model = Model(inp, out)#, name=base_model.name)
            print('Trying multi-gpu model')
            model = multi_gpu_compile(model)
            # ---------------------
        else:
            model = define_model(architecture=architecture, input_shape=(None, None, N), BACKBONE=backbone, encoder_weights=None)
            print('Trying multi-gpu model')
            model = multi_gpu_compile(model)

        # -----------------------------------------------------------------------------------------
        # running the model_run outside of the function    
        print('Compiling with Adam, jaccard_loss, iou_score')
        opt = Adam(lr=learning_rate)
        model.compile(opt, loss=jaccard_loss, metrics=[iou_score, f_score, f1_m, 
                                                       precision_m, recall_m])
        print('model compiled')
        # print(model.summary())
        
        # -----------------------------------------------------------------------------------------
        
        

        
        
        
        
        
        filepath=path + '/' + str(date)+'_'+str(architecture)+'_'+str(backbone)+'_'+str(weightusage)+'_'+'_'+clstype+'weightsbest.h5'
        #filepath=path + '/' + str(date)+'_'+str(architecture)+'_'+str(backbone)+'_'+str(weightusage)+'_'+"_FilteredFieldsweightsbest.h5"
        # Checking if there is already trained weights for the model
        print(filepath)
        if os.path.isfile(filepath):
            print('loading weights of best model for date : ',str(date),' and backbone :',str(filepath))
            model.load_weights(filepath)
        else:
          print('No trainable weights found')



          
          

        if training == 'Yes':
            # Creating the callbacks
            checkpoint = ModelCheckpoint(filepath, monitor='val_iou_score', verbose=1, save_best_only=True, 
                                         save_weights_only=True, mode='max')
            tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=False, 
                                      write_grads=False,  write_images=True, embeddings_freq=0, 
                                      embeddings_layer_names=None, embeddings_metadata=None, 
                                      embeddings_data=None, update_freq=1600)
            reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3, verbose=1, mode='auto',
                                         min_delta=0.0001, cooldown=0, min_lr=0)

            # Can add early stopping Callback here as well

            callbacks_list = [WandbCallback(),checkpoint, tensorboard, reduceLR]
            print('Callbacks Defined')


            history = model.fit_generator(train_gen, 
                                          steps_per_epoch=int(len(ids_train_split)/batch_size),
                                          validation_data=test_gen, 
                                          validation_steps=int(len(ids_test_split)/batch_size), 
                        epochs=epochs, verbose=1, callbacks=callbacks_list)
            print('model fitted')
            print(datetime.now())
            histories.update({architecture+'_'+backbone+'_'+date:history.history})

            timestr = time.strftime("%Y%m%d-%H%M%S")  
            model.save_weights(str(filepath[:-7])+'final_after'+str(epochs)+'epochs.h5')

            print('Model Evaluation')
            print(datetime.now())


        


        
        
        
        
        # Predicting from the models
        imgprefix = path + '/predictions/' + str(date)+'_'+str(architecture)+'_'+str(backbone)+'_'+str(weightusage)+'_'+'_'+clstype


        
        if predictions == 'Yes':
            if not os.path.exists(path+'/predictions/'+clstype+'/'):
                os.makedirs(path+'/predictions/'+clstype+'/'+'val/')
                os.makedirs(path+'/predictions/'+clstype+'/'+'test/')
                os.makedirs(path+'/predictions/'+clstype+'/'+'train/')

            layer_name = '3rd_Conv'
            intermediate_layer_model = Model(inputs=model.input,
                              outputs=model.get_layer(layer_name).output)






            for i in range(5):
                inum = int(len(ids_val_split)*((i*2)/10)) 
                id = ids_val_split[inum]
                img = io.imread('val/tifs/images/'+str(id))
                #mask = io.imread('val/labels/masks/'+str(id))
                #mask = np.expand_dims(mask, axis=2)
                img = np.array(img, np.float32) / 65535
                img = expand_dims(img,axis=0)
                #testy1 = expand_dims(testY[inum],axis=0)        
                predy=model.predict(img)
                iout = intermediate_layer_model.predict(img)
                io.imsave(path+'/predictions/'+clstype+'/'+'val/iout_'+str(id), iout)
                io.imsave(path+'/predictions/'+clstype+'/'+'val/val_'+str(id), predy)

            print('\nVal predictions saved')         

            for i in range(5):
                inum = int(len(ids_test_split)*((i*2)/10)) 
                id = ids_test_split[inum]
                img = io.imread('test/tifs/images/'+str(id))
                img = np.array(img, np.float32) / 65535   
                img = expand_dims(img,axis=0)
                predy=model.predict(img)
                iout = intermediate_layer_model.predict(img)
                io.imsave(path+'/predictions/'+clstype+'/'+'test/iout_'+str(id), iout)
                io.imsave(path+'/predictions/'+clstype+'/'+'test/test_'+str(id), predy)


            print('\nTest predictions saved')               

            for i in range(5):
                inum = int(len(ids_train_split)*((i*2)/10)) 
                id = ids_train_split[inum]
                img = io.imread('train/tifs/images/'+str(id))
                img = np.array(img, np.float32) / 65535
                img = expand_dims(img,axis=0)
                predy=model.predict(img)
                iout = intermediate_layer_model.predict(img)
                io.imsave(path+'/predictions/'+clstype+'/'+'train/iout_'+str(id), iout)
                io.imsave(path+'/predictions/'+clstype+'/'+'train/train_'+str(id), predy)


            print('\nTrain predictions saved')
          




        ids_val_split = os.listdir('val/tifs/images/')
        print('Length of val ids ', len(ids_val_split))
        
        val_gen = val_generator(ids_val_split, batch_size)


        loss, iou, fscore, f1_score, precision, recall = model.evaluate_generator(val_gen, 
                                                               steps=int(len(ids_val_split)/batch_size), 
                                                                                  verbose=1)
        
        
        print('> loss=%.3f, iou=%.3f, fscore=%.3f,f1score=%.3f,precision=%.3f,recall=%.3f,'\
#               % (loss, iou,fscore, f1_score, precision, recall))
        # learning curves
        print('####### Run Complete ########')
        #path= os.getcwd()
        #summarize_diagnostics(history, backbone, architecture, filepath)
        timestr = time.strftime("%Y%m%d-%H%M%S")
        
        
          

        # Checking the confusion matrices
        print('Checking the confusion matrices on the validation data')
        if accuracies == 'Yes':
            preds = []
            true = []
            for i in range(len(ids_val_split)):
                id = ids_val_split[i]
                img = io.imread('val/tifs/images/'+str(id))
                mask = io.imread('val/labels/masks/'+str(id))
                mask = np.expand_dims(mask, axis=0)
                img = np.array(img, np.float32) / 65535
                img = expand_dims(img,axis=0)
                #testy1 = expand_dims(testY[inum],axis=0)        
                predy=model.predict(img)
                predy=np.argmax(predy,axis=3)
                preds.append(predy)
                true.append(mask)
            preds=(np.array(preds).flatten())
            true= (np.array(true).flatten())
            print(preds.shape)
            print(true.shape)

true = []
for i in range(len(ids_test_split)):
    id = ids_val_split[i]
    img = io.imread('val/tifs/images/'+str(id))
    mask = io.imread('val/labels/masks/'+str(id))
    mask = np.expand_dims(mask, axis=0)
    img = np.array(img, np.float32) / 65535
    img = expand_dims(img,axis=0)
    #testy1 = expand_dims(testY[inum],axis=0)        
    predy=model.predict(img)
    predy=np.argmax(predy,axis=3)

    preds.append(predy)
    true.append(mask)
preds=(np.array(preds).flatten())
true= (np.array(true).flatten())
print(preds.shape)
print(true.shape)

classes = unique_labels(preds, true)

preds.shape

np.set_printoptions(precision=2)
# Plot non-normalized confusion matrix
plot_confusion_matrix(true, preds, classes=classes,
                      title='Confusion matrix, without normalization')
# Plot normalized confusion matrix
plot_confusion_matrix(true, preds, classes=classes, normalize=True,
                      title='Normalized confusion matrix')

classes_labels = {0:'Background',1:'InnerFields',2:'Boundaries'}

from sklearn.metrics import classification_report, confusion_matrix
conf_matrix = confusion_matrix(true,preds)
print(conf_matrix)
class_report = classification_report(true,preds)
print(class_report)

precision_recall_fscore_support(true,preds)

"""## Check Conf Matrix on Test"""

print('Checking the confusion matrices on the test data')
if accuracies == 'Yes':
    predst = []
    truet = []
    for i in range(len(ids_test_split)):
        id = ids_test_split[i]
        img = io.imread('test/tifs/images/'+str(id))
        mask = io.imread('test/labels/masks/'+str(id))
        mask = np.expand_dims(mask, axis=0)
        img = np.array(img, np.float32) / 65535
        img = expand_dims(img,axis=0)
        #testy1 = expand_dims(testY[inum],axis=0)        
        predy=model.predict(img)
        predy=np.argmax(predy,axis=3)
        predst.append(predy)
        truet.append(mask)
    predst=(np.array(predst).flatten())
    truet= (np.array(truet).flatten())
    print(predst.shape)
    print(truet.shape)

        #del history
        #del model
        #gc.collect()

# import json

# with open(path+'/'+Satellite+Exp+'_'+'histories.json', 'w') as fp:
#     json.dump(histories, fp)

from sklearn.utils.multiclass import unique_labels
classest = unique_labels(predst, truet)

np.set_printoptions(precision=2)
# Plot non-normalized confusion matrix
plot_confusion_matrix(truet, predst, classes=classest,
                      title='Confusion matrix, without normalization')
# Plot normalized confusion matrix
plot_confusion_matrix(truet, predst, classes=classest, normalize=True,
                      title='Normalized confusion matrix')

from sklearn.metrics import classification_report, confusion_matrix
conf_matrixt = confusion_matrix(truet,predst)
print(conf_matrixt)
class_reportt = classification_report(truet,predst)
print(class_reportt)

from sklearn.metrics import precision_recall_fscore_support

PRF_t=precision_recall_fscore_support(truet,predst)
print(PRF_t)

"""## Check Conf Matrix for train"""



print('Checking the confusion matrices on the train data')
if accuracies == 'Yes':
    predstr = []
    truetr = []
    for i in range(len(ids_train_split)):
        id = ids_train_split[i]
        img = io.imread('train/tifs/images/'+str(id))
        mask = io.imread('train/labels/masks/'+str(id))
        mask = np.expand_dims(mask, axis=0)
        img = np.array(img, np.float32) / 65535
        img = expand_dims(img,axis=0)
        #testy1 = expand_dims(testY[inum],axis=0)        
        predy=model.predict(img)
        predy=np.argmax(predy,axis=3)
        predstr.append(predy)
        truetr.append(mask)
    predstr=(np.array(predstr).flatten())
    truetr= (np.array(truetr).flatten())
    print(predstr.shape)
    print(truetr.shape)

        #del history
        #del model
        #gc.collect()

# import json

# with open(path+'/'+Satellite+Exp+'_'+'histories.json', 'w') as fp:
#     json.dump(histories, fp)

from sklearn.utils.multiclass import unique_labels
classestr = unique_labels(predstr, truetr)

np.set_printoptions(precision=2)
# Plot non-normalized confusion matrix
plot_confusion_matrix(truetr, predstr, classes=classestr,
                      title='Confusion matrix, without normalization')
# Plot normalized confusion matrix
plot_confusion_matrix(truetr, predstr, classes=classestr, normalize=True,
                      title='Normalized confusion matrix')

conf_matrixtr = confusion_matrix(truetr,predstr)
print(conf_matrixtr)
class_reporttr = classification_report(truetr,predstr)
print(class_reporttr)

PRF_tr=precision_recall_fscore_support(truetr,predstr)
print(PRF_tr)